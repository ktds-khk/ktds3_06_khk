import streamlit as st
import pandas as pd
from datetime import datetime
import os
from dotenv import load_dotenv
from azure.storage.blob import BlobServiceClient
from azure.search.documents import SearchClient
from azure.core.credentials import AzureKeyCredential
import openai
import json
import plotly.express as px
import plotly.graph_objects as go
from io import StringIO

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# Azure ì„¤ì •
STORAGE_CONNECTION_STRING = os.getenv("STORAGE_CONNECTION_STRING")
SEARCH_ENDPOINT = os.getenv("SEARCH_ENDPOINT")
SEARCH_KEY = os.getenv("SEARCH_KEY")
SEARCH_INDEX_NAME = "ito-events-index"
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_ENDPOINT = os.getenv("OPENAI_ENDPOINT")
OPENAI_DEPLOYMENT = os.getenv("OPENAI_DEPLOYMENT")

# Azure OpenAI ì„¤ì •
OPENAI_CLIENT = None
OPENAI_VERSION = None

if OPENAI_API_KEY and OPENAI_ENDPOINT:
    try:
        # ë²„ì „ í™•ì¸
        import openai
        openai_version = openai.__version__
        
        if openai_version.startswith('0.'):
            # êµ¬ë²„ì „ (0.28.x)
            openai.api_type = "azure"
            openai.api_base = OPENAI_ENDPOINT
            openai.api_version = "2024-02-01"
            openai.api_key = OPENAI_API_KEY
            OPENAI_VERSION = "0.28"
        else:
            # ì‹ ë²„ì „ (1.0+)
            try:
                from openai import AzureOpenAI
                client = AzureOpenAI(
                    api_key=OPENAI_API_KEY,
                    api_version="2024-02-01",
                    azure_endpoint=OPENAI_ENDPOINT
                )
                OPENAI_CLIENT = client
                OPENAI_VERSION = "1.0+"
            except Exception as e:
                # ì‹ ë²„ì „ ì´ˆê¸°í™” ì‹¤íŒ¨ ì‹œ êµ¬ë²„ì „ ë°©ì‹ ì‹œë„
                st.warning(f"OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
                OPENAI_VERSION = None
    except ImportError:
        st.error("OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'pip install openai==0.28.1' ëª…ë ¹ìœ¼ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”.")
        OPENAI_VERSION = None

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ITO ì´ë²¤íŠ¸ ë¶„ì„ agent",
    page_icon="ğŸ“Š",
    layout="wide"
)

# ìŠ¤íƒ€ì¼ ì„¤ì •
st.markdown("""
<style>
    .stButton > button {
        background-color: #0066cc;
        color: white;
        border-radius: 5px;
        padding: 0.5rem 1rem;
        border: none;
        transition: background-color 0.3s;
    }
    .stButton > button:hover {
        background-color: #0052a3;
    }
    .metric-card {
        background-color: #f0f0f0;
        padding: 20px;
        border-radius: 10px;
        text-align: center;
        margin: 10px 0;
    }
</style>
""", unsafe_allow_html=True)

# í—¬í¼ í•¨ìˆ˜ë“¤ ì •ì˜
def calculate_average_duration(duration_series):
    """Duration ë¬¸ìì—´ì„ íŒŒì‹±í•˜ì—¬ í‰ê·  ê³„ì‚°"""
    try:
        total_seconds = 0
        count = 0
        
        for duration in duration_series:
            if pd.notna(duration) and duration != '':
                # Duration í˜•ì‹ íŒŒì‹± (ì˜ˆ: "1h 30m", "45m", "2d 3h")
                seconds = parse_duration_to_seconds(duration)
                if seconds > 0:
                    total_seconds += seconds
                    count += 1
        
        if count > 0:
            avg_seconds = total_seconds / count
            return format_seconds_to_duration(avg_seconds)
        return "N/A"
    except:
        return "N/A"

def parse_duration_to_seconds(duration_str):
    """Duration ë¬¸ìì—´ì„ ì´ˆ ë‹¨ìœ„ë¡œ ë³€í™˜"""
    try:
        total_seconds = 0
        parts = duration_str.strip().split()
        
        for part in parts:
            if 'd' in part:
                days = int(part.replace('d', ''))
                total_seconds += days * 86400
            elif 'h' in part:
                hours = int(part.replace('h', ''))
                total_seconds += hours * 3600
            elif 'm' in part:
                minutes = int(part.replace('m', ''))
                total_seconds += minutes * 60
            elif 's' in part:
                seconds = int(part.replace('s', ''))
                total_seconds += seconds
                
        return total_seconds
    except:
        return 0

def format_seconds_to_duration(seconds):
    """ì´ˆë¥¼ ì½ê¸° ì‰¬ìš´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    if seconds < 60:
        return f"{int(seconds)}ì´ˆ"
    elif seconds < 3600:
        return f"{int(seconds/60)}ë¶„"
    elif seconds < 86400:
        hours = int(seconds/3600)
        minutes = int((seconds % 3600) / 60)
        return f"{hours}ì‹œê°„ {minutes}ë¶„"
    else:
        days = int(seconds/86400)
        hours = int((seconds % 86400) / 3600)
        return f"{days}ì¼ {hours}ì‹œê°„"

# ê°„ëµí™”ëœ AI ë¶„ì„ í•¨ìˆ˜
def perform_simple_ai_analysis(df):
    """ê°„ë‹¨í•œ AI ì¢…í•© ë¶„ì„"""
    try:
        # OpenAI ì„¤ì • í™•ì¸
        if not OPENAI_VERSION:
            return "AI ë¶„ì„ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. OpenAI ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”."
        
        # ë°ì´í„° ìš”ì•½
        total_events = len(df)
        
        # Severity ì»¬ëŸ¼ ì°¾ê¸°
        severity_col = None
        for col in ['Severity', 'severity', 'SEVERITY', 'ì‹¬ê°ë„', 'Level', 'level']:
            if col in df.columns:
                severity_col = col
                break
        
        if severity_col:
            df_severity = df.copy()
            df_severity[severity_col] = df_severity[severity_col].astype(str).str.lower()
            critical_events = len(df_severity[df_severity[severity_col].isin(['disaster', 'high', 'fatal', 'critical', 'error'])])
            warning_events = len(df_severity[df_severity[severity_col].isin(['average', 'warning', 'major', 'medium'])])
        else:
            critical_events = 0
            warning_events = 0
        
        unique_hosts = df['Host'].nunique() if 'Host' in df.columns else 0
        
        # ìƒìœ„ ë¬¸ì œ
        top_issues = df['Description'].value_counts().head(10).to_dict() if 'Description' in df.columns else {}
        
        # ì‹œê°„ ë¶„ì„
        time_analysis = {}
        if 'Time' in df.columns:
            df_time = df.copy()
            df_time['Time'] = pd.to_datetime(df_time['Time'])
            df_time['Hour'] = df_time['Time'].dt.hour
            hourly_counts = df_time.groupby('Hour').size()
            peak_hours = hourly_counts.nlargest(3).to_dict()
            
            # ìµœê·¼ 24ì‹œê°„ vs ì´ì „ 24ì‹œê°„ ë¹„êµ
            latest_time = df_time['Time'].max()
            recent_24h = len(df_time[df_time['Time'] >= latest_time - pd.Timedelta(hours=24)])
            previous_24h = len(df_time[(df_time['Time'] >= latest_time - pd.Timedelta(hours=48)) & 
                                      (df_time['Time'] < latest_time - pd.Timedelta(hours=24))])
            
            time_analysis = {
                "peak_hours": peak_hours,
                "recent_24h": recent_24h,
                "previous_24h": previous_24h,
                "trend": "ì¦ê°€" if recent_24h > previous_24h else "ê°ì†Œ",
                "change_rate": ((recent_24h - previous_24h) / previous_24h * 100) if previous_24h > 0 else 0
            }
        
        # í˜¸ìŠ¤íŠ¸ë³„ ë¶„ì„
        host_analysis = {}
        if 'Host' in df.columns:
            host_counts = df['Host'].value_counts()
            top_hosts = host_counts.head(5).to_dict()
            avg_events_per_host = total_events / unique_hosts if unique_hosts > 0 else 0
            
            # ë¬¸ì œê°€ ë§ì€ í˜¸ìŠ¤íŠ¸
            if 'Status' in df.columns:
                problem_hosts = df[df['Status'] == 'PROBLEM']['Host'].value_counts().head(5).to_dict()
            else:
                problem_hosts = {}
            
            host_analysis = {
                "top_hosts": top_hosts,
                "avg_events_per_host": avg_events_per_host,
                "problem_hosts": problem_hosts
            }
        
        # ìƒ˜í”Œ ë°ì´í„° ì¤€ë¹„
        sample_df = df.head(100).copy()
        if 'Time' in sample_df.columns:
            sample_df['Time'] = sample_df['Time'].astype(str)
        sample_data = sample_df.to_dict('records')
        
        prompt = f"""
        ë‹¤ìŒ Zabbix/ITO ì´ë²¤íŠ¸ ë°ì´í„°ë¥¼ ìƒì„¸íˆ ë¶„ì„í•´ì£¼ì„¸ìš”:
        
        === ë°ì´í„° ìš”ì•½ ===
        ì´ ì´ë²¤íŠ¸: {total_events}
        ì‹¬ê° ì´ë²¤íŠ¸ (fatal/critical/high): {critical_events} ({(critical_events/total_events*100):.1f}%)
        ê²½ê³  ì´ë²¤íŠ¸ (major/warning): {warning_events} ({(warning_events/total_events*100):.1f}%)
        ì˜í–¥ í˜¸ìŠ¤íŠ¸: {unique_hosts}
        
        === ì‹œê°„ ë¶„ì„ ===
        {json.dumps(time_analysis, ensure_ascii=False, indent=2)}
        
        === í˜¸ìŠ¤íŠ¸ ë¶„ì„ ===
        {json.dumps(host_analysis, ensure_ascii=False, indent=2)}
        
        === ì£¼ìš” ë¬¸ì œ Top 10 ===
        {json.dumps(top_issues, ensure_ascii=False, indent=2)}
        
        === ìƒ˜í”Œ ì´ë²¤íŠ¸ ë°ì´í„° ===
        {json.dumps(sample_data[:50], ensure_ascii=False, indent=2)[:3000]}
        
        ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ìƒì„¸í•˜ê³  êµ¬ì¡°í™”ëœ ë¶„ì„ì„ ì œê³µí•´ì£¼ì„¸ìš”:
        
        ## 1. ğŸ” í˜„ì¬ ì‹œìŠ¤í…œ ìƒíƒœ ì§„ë‹¨
        ### ì „ë°˜ì  ìƒíƒœ: [ì–‘í˜¸/ì£¼ì˜/ê²½ê³ /ìœ„í—˜]
        - ì¢…í•© í‰ê°€ì™€ ê·¼ê±°
        - ì£¼ìš” ì§€í‘œë³„ ìƒíƒœ
        - ì¦‰ê°ì ì¸ ì£¼ì˜ê°€ í•„ìš”í•œ ì‚¬í•­
        
        ## 2. ğŸš¨ ì£¼ìš” ë¬¸ì œì  ë¶„ì„ (ìš°ì„ ìˆœìœ„ìˆœ)
        ### ë¬¸ì œ 1: [ë¬¸ì œëª…]
        - ì˜í–¥ë„: [ë†’ìŒ/ì¤‘ê°„/ë‚®ìŒ]
        - ë°œìƒ ë¹ˆë„: Xê±´ (Y%)
        - ì˜í–¥ë°›ëŠ” ì‹œìŠ¤í…œ/í˜¸ìŠ¤íŠ¸: 
        - ì˜ˆìƒ ì›ì¸:
        - ê¶Œì¥ ì¡°ì¹˜:
        
        ### ë¬¸ì œ 2: [ë¬¸ì œëª…]
        - (ë™ì¼ í˜•ì‹)
        
        ### ë¬¸ì œ 3: [ë¬¸ì œëª…]
        - (ë™ì¼ í˜•ì‹)
        
        ## 3. ğŸ“Š íŒ¨í„´ ë° íŠ¸ë Œë“œ ë¶„ì„
        ### ì‹œê°„ì  íŒ¨í„´
        - í”¼í¬ ì‹œê°„ëŒ€ì™€ ì›ì¸ ë¶„ì„
        - 24ì‹œê°„ íŠ¸ë Œë“œ (ì¦ê°€/ê°ì†Œ ë° ë³€í™”ìœ¨)
        - ì£¼ê¸°ì  íŒ¨í„´ ìœ ë¬´
        
        ### í˜¸ìŠ¤íŠ¸ë³„ íŒ¨í„´
        - ë¬¸ì œê°€ ì§‘ì¤‘ëœ í˜¸ìŠ¤íŠ¸
        - í˜¸ìŠ¤íŠ¸ ê°„ ìƒê´€ê´€ê³„
        - íŠ¹ì´ íŒ¨í„´ ë°œê²¬ì‚¬í•­
        
        ## 4. ğŸ¯ ì¦‰ì‹œ ì¡°ì¹˜ì‚¬í•­ (Action Items)
        ### ê¸´ê¸‰ (24ì‹œê°„ ë‚´)
        1. [êµ¬ì²´ì  ì¡°ì¹˜ì‚¬í•­]
        2. [êµ¬ì²´ì  ì¡°ì¹˜ì‚¬í•­]
        
        ### ë‹¨ê¸° (1ì£¼ì¼ ë‚´)
        1. [êµ¬ì²´ì  ì¡°ì¹˜ì‚¬í•­]
        2. [êµ¬ì²´ì  ì¡°ì¹˜ì‚¬í•­]
        
        ### ì¤‘ì¥ê¸° ê°œì„ ì‚¬í•­
        1. [êµ¬ì²´ì  ì¡°ì¹˜ì‚¬í•­]
        2. [êµ¬ì²´ì  ì¡°ì¹˜ì‚¬í•­]
        
        ## 5. ğŸ’¡ ì¶”ê°€ ê¶Œì¥ì‚¬í•­
        - ëª¨ë‹ˆí„°ë§ ê°•í™” í¬ì¸íŠ¸
        - ì„ê³„ê°’ ì¡°ì • ì œì•ˆ
        - í”„ë¡œì„¸ìŠ¤ ê°œì„  ì œì•ˆ
        
        ê° ì„¹ì…˜ì„ êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ë‚´ìš©ìœ¼ë¡œ ì‘ì„±í•˜ê³ , ë°ì´í„°ì— ê¸°ë°˜í•œ ì •ëŸ‰ì  ê·¼ê±°ë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”.
        """
        
        # OpenAI API í˜¸ì¶œ (ë²„ì „ë³„ ë¶„ê¸°)
        if OPENAI_VERSION == "1.0+" and OPENAI_CLIENT:
            # ìƒˆë¡œìš´ API (1.0+)
            response = OPENAI_CLIENT.chat.completions.create(
                model=OPENAI_DEPLOYMENT,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ IT ì¸í”„ë¼ ëª¨ë‹ˆí„°ë§ ë° ì¥ì•  ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=2000,
                temperature=0.7
            )
            return response.choices[0].message.content
        elif OPENAI_VERSION == "0.28":
            # êµ¬ë²„ì „ API (0.28)
            response = openai.ChatCompletion.create(
                engine=OPENAI_DEPLOYMENT,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ IT ì¸í”„ë¼ ëª¨ë‹ˆí„°ë§ ë° ì¥ì•  ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=2000,
                temperature=0.7
            )
            return response.choices[0].message.content
        else:
            return "AI ë¶„ì„ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. OpenAI ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”."
        
    except Exception as e:
        return f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

def create_visualizations(df):
    """ë°ì´í„° ì‹œê°í™”"""
    st.subheader("ğŸ“ˆ ì‹œê°í™” ëŒ€ì‹œë³´ë“œ")
    
    # DataFrame ë³µì‚¬ë³¸ ìƒì„±
    df = df.copy()
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Severityë³„ ë¶„í¬
        if 'Severity' in df.columns:
            severity_counts = df['Severity'].value_counts()
            
            # ìƒ‰ìƒ ë§¤í•‘ (Zabbix í‘œì¤€)
            colors = {
                'Disaster': '#E45959',
                'High': '#E97659',
                'Average': '#FFA059',
                'Warning': '#FFC859',
                'Information': '#7499FF',
                'Not classified': '#97AAB3'
            }
            
            fig = px.pie(
                values=severity_counts.values, 
                names=severity_counts.index,
                title='ì‹¬ê°ë„ë³„ ì´ë²¤íŠ¸ ë¶„í¬',
                color=severity_counts.index,
                color_discrete_map=colors
            )
            st.plotly_chart(fig, use_container_width=True)
        
        # Hostë³„ ì´ë²¤íŠ¸ ìˆ˜
        if 'Host' in df.columns:
            top_hosts = df['Host'].value_counts().head(10)
            fig = px.bar(
                x=top_hosts.values,
                y=top_hosts.index,
                orientation='h',
                title='í˜¸ìŠ¤íŠ¸ë³„ ì´ë²¤íŠ¸ ë°œìƒ ìˆ˜ (Top 10)',
                labels={'x': 'ì´ë²¤íŠ¸ ìˆ˜', 'y': 'í˜¸ìŠ¤íŠ¸'}
            )
            st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        # ì‹œê°„ë³„ ì´ë²¤íŠ¸ ë°œìƒ ì¶”ì´
        if 'Time' in df.columns:
            df['Time'] = pd.to_datetime(df['Time'])
            
            # ì‹œê°„ëŒ€ë³„ ì§‘ê³„
            df['Hour'] = df['Time'].dt.hour
            hourly_counts = df.groupby(['Hour', 'Severity']).size().reset_index(name='count')
            
            fig = px.line(
                hourly_counts,
                x='Hour',
                y='count',
                color='Severity',
                title='ì‹œê°„ëŒ€ë³„ ì´ë²¤íŠ¸ ë°œìƒ ì¶”ì´',
                labels={'Hour': 'ì‹œê°„', 'count': 'ì´ë²¤íŠ¸ ìˆ˜'}
            )
            st.plotly_chart(fig, use_container_width=True)
        
        # Statusë³„ ë¶„í¬
        if 'Status' in df.columns:
            status_counts = df['Status'].value_counts()
            fig = px.pie(
                values=status_counts.values,
                names=status_counts.index,
                title='ì´ë²¤íŠ¸ ìƒíƒœ ë¶„í¬',
                color_discrete_map={'OK': '#59DB8F', 'PROBLEM': '#E45959'}
            )
            st.plotly_chart(fig, use_container_width=True)

def perform_analysis(analysis_type, time_range):
    """ì„ íƒëœ ë¶„ì„ ìˆ˜í–‰"""
    with st.spinner(f"{analysis_type} ìˆ˜í–‰ ì¤‘..."):
        # ì—¬ê¸°ì— ì‹¤ì œ ë¶„ì„ ë¡œì§ êµ¬í˜„
        st.success(f"âœ… {analysis_type} ì™„ë£Œ!")
        
        # ìƒ˜í”Œ ê²°ê³¼
        st.markdown(f"""
        ### {analysis_type} ê²°ê³¼
        
        **ë¶„ì„ ê¸°ê°„**: {time_range}
        
        **ì£¼ìš” ë°œê²¬ì‚¬í•­**:
        - íŒ¨í„´ 1: íŠ¹ì • ì‹œê°„ëŒ€ì— ì´ë²¤íŠ¸ ì§‘ì¤‘
        - íŒ¨í„´ 2: íŠ¹ì • ì„œë¹„ìŠ¤ì˜ ë°˜ë³µì  ì˜¤ë¥˜
        - íŒ¨í„´ 3: ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ì¦ê°€ ì¶”ì„¸
        
        **ê¶Œì¥ì‚¬í•­**:
        1. í”¼í¬ ì‹œê°„ëŒ€ ë¦¬ì†ŒìŠ¤ ì¦ì„¤ ê³ ë ¤
        2. ì˜¤ë¥˜ ë°œìƒ ì„œë¹„ìŠ¤ ì ê²€ í•„ìš”
        3. ì˜ˆë°©ì  ëª¨ë‹ˆí„°ë§ ê°•í™”
        """)

def generate_report(report_type):
    """ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±"""
    # ë°ì´í„° í™•ì¸
    if 'event_data' not in st.session_state and 'event_files' not in st.session_state:
        st.error("ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.")
        return
    
    with st.spinner("ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„± ì¤‘..."):
        # ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        if 'event_data' in st.session_state:
            df = st.session_state['event_data'].copy()
        else:
            dfs = [data['data'] for data in st.session_state['event_files'].values()]
            df = pd.concat(dfs, ignore_index=True)
        
        # ì‹œê°„ ì²˜ë¦¬
        if 'Time' in df.columns:
            df['Time'] = pd.to_datetime(df['Time'])
        
        # í†µê³„ ê³„ì‚°
        total_events = len(df)
        
        # Severity ì»¬ëŸ¼ ì°¾ê¸°
        severity_col = None
        for col in ['Severity', 'severity', 'SEVERITY', 'ì‹¬ê°ë„', 'Level', 'level']:
            if col in df.columns:
                severity_col = col
                break
        
        if severity_col:
            critical_events = len(df[df[severity_col].str.lower().isin(['disaster', 'high', 'fatal', 'critical', 'error'])]) 
            warning_events = len(df[df[severity_col].str.lower().isin(['average', 'warning', 'major', 'medium'])])
            info_events = len(df[df[severity_col].str.lower().isin(['information', 'info', 'low', 'not classified'])])
        else:
            critical_events = 0
            warning_events = 0
            info_events = 0
        
        problem_events = len(df[df['Status'] == 'PROBLEM']) if 'Status' in df.columns else 0
        ok_events = len(df[df['Status'] == 'OK']) if 'Status' in df.columns else 0
        
        unique_hosts = df['Host'].nunique() if 'Host' in df.columns else 0
        top_hosts = df['Host'].value_counts().head(10) if 'Host' in df.columns else pd.Series()
        
        # ì‹œê°„ ì •ë³´
        if 'Time' in df.columns:
            time_range = f"{df['Time'].min().strftime('%Y-%m-%d %H:%M')} ~ {df['Time'].max().strftime('%Y-%m-%d %H:%M')}"
            total_days = (df['Time'].max() - df['Time'].min()).days + 1
            peak_hour = df.groupby(df['Time'].dt.hour).size().idxmax()
            
            # ì¼ë³„ í†µê³„
            daily_stats = df.groupby(df['Time'].dt.date).size()
            daily_avg = daily_stats.mean()
            daily_max = daily_stats.max()
            daily_min = daily_stats.min()
            
            # ì‹œê°„ëŒ€ë³„ ë¶„í¬
            hourly_dist = df.groupby(df['Time'].dt.hour).size()
        else:
            time_range = "N/A"
            total_days = 0
            peak_hour = "N/A"
            daily_avg = 0
            daily_max = 0
            daily_min = 0
            hourly_dist = pd.Series()
        
        # Duration ë¶„ì„
        if 'Duration' in df.columns:
            df['Duration_seconds'] = df['Duration'].apply(parse_duration_to_seconds)
            avg_duration = df[df['Duration_seconds'] > 0]['Duration_seconds'].mean()
            max_duration = df[df['Duration_seconds'] > 0]['Duration_seconds'].max()
            avg_duration_str = format_seconds_to_duration(avg_duration) if not pd.isna(avg_duration) else "N/A"
            max_duration_str = format_seconds_to_duration(max_duration) if not pd.isna(max_duration) else "N/A"
        else:
            avg_duration_str = "N/A"
            max_duration_str = "N/A"
        
        # ìƒìœ„ ë¬¸ì œ
        top_issues = df['Description'].value_counts().head(15) if 'Description' in df.columns else pd.Series()
        
        # ë¦¬í¬íŠ¸ ë‚´ìš© ìƒì„±
        report_content = f"""# ITO ì´ë²¤íŠ¸ ì¢…í•© ë¦¬í¬íŠ¸
        
ìƒì„±ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
ë¶„ì„ ê¸°ê°„: {time_range}
ì´ ë¶„ì„ ì¼ìˆ˜: {total_days}ì¼

================================================================================

## ğŸ“Š ì „ì²´ ìš”ì•½
- ì´ ì´ë²¤íŠ¸ ìˆ˜: {total_events:,}
- ì¼í‰ê·  ì´ë²¤íŠ¸: {daily_avg:.1f}ê±´
- ì¼ ìµœëŒ€ ì´ë²¤íŠ¸: {daily_max:,}ê±´
- ì¼ ìµœì†Œ ì´ë²¤íŠ¸: {daily_min:,}ê±´

## ğŸš¨ ì‹¬ê°ë„ ë¶„ì„
- ì‹¬ê° ì´ë²¤íŠ¸ (Fatal/Critical/High): {critical_events:,}ê±´ ({(critical_events/total_events*100):.1f}%)
- ê²½ê³  ì´ë²¤íŠ¸ (Major/Average/Warning): {warning_events:,}ê±´ ({(warning_events/total_events*100):.1f}%)
- ì •ë³´ ì´ë²¤íŠ¸ (Information/Low): {info_events:,}ê±´ ({(info_events/total_events*100):.1f}%)
- í•´ê²°ëœ ì´ë²¤íŠ¸ (OK): {ok_events:,}ê±´
- ë¬¸ì œ ì´ë²¤íŠ¸ (PROBLEM): {problem_events:,}ê±´

## ğŸ–¥ï¸ í˜¸ìŠ¤íŠ¸ ë¶„ì„
- ì˜í–¥ë°›ì€ í˜¸ìŠ¤íŠ¸ ìˆ˜: {unique_hosts}ê°œ
- í˜¸ìŠ¤íŠ¸ë‹¹ í‰ê·  ì´ë²¤íŠ¸: {(total_events/unique_hosts):.1f}ê±´

### ê°€ì¥ ë§ì€ ì´ë²¤íŠ¸ ë°œìƒ í˜¸ìŠ¤íŠ¸ Top 10:
"""
        
        for i, (host, count) in enumerate(top_hosts.items(), 1):
            percentage = (count / total_events * 100)
            report_content += f"  {i:2d}. {host}: {count:,}ê±´ ({percentage:.1f}%)\n"
        
        report_content += f"""
## â° ì‹œê°„ ë¶„ì„
- í”¼í¬ ì‹œê°„ëŒ€: {peak_hour}ì‹œ
- í‰ê·  ì´ë²¤íŠ¸ ì§€ì† ì‹œê°„: {avg_duration_str}
- ìµœëŒ€ ì´ë²¤íŠ¸ ì§€ì† ì‹œê°„: {max_duration_str}

### ì‹œê°„ëŒ€ë³„ ì´ë²¤íŠ¸ ë¶„í¬:
"""
        
        # ì‹œê°„ëŒ€ë³„ ë¶„í¬ ì¶”ê°€
        if not hourly_dist.empty:
            peak_hours = hourly_dist.nlargest(5)
            for hour, count in peak_hours.items():
                report_content += f"  - {hour:02d}ì‹œ: {count:,}ê±´\n"
        
        report_content += """
## ğŸš¨ ì£¼ìš” ë¬¸ì œ (Top 15)
"""
        for i, (issue, count) in enumerate(top_issues.items(), 1):
            percentage = (count / total_events * 100)
            report_content += f"{i:2d}. {issue[:100]}{'...' if len(issue) > 100 else ''}\n"
            report_content += f"    - ë°œìƒ íšŸìˆ˜: {count:,}ê±´ ({percentage:.1f}%)\n"
        
        report_content += """
================================================================================
"""
        
        st.success("âœ… ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ!")
        
        # ë¦¬í¬íŠ¸ ë¯¸ë¦¬ë³´ê¸°
        with st.expander("ğŸ“„ ë¦¬í¬íŠ¸ ë¯¸ë¦¬ë³´ê¸°", expanded=True):
            st.text(report_content)
        
        # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
        col1, col2, col3 = st.columns([1, 1, 2])
        with col1:
            st.download_button(
                label="ğŸ“¥ í…ìŠ¤íŠ¸ ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ",
                data=report_content,
                file_name=f"ITO_ì¢…í•©ë¦¬í¬íŠ¸_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                mime="text/plain",
                type="primary"
            )
        
        with col2:
            # CSV í˜•ì‹ìœ¼ë¡œë„ ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥
            summary_data = {
                'í•­ëª©': ['ì´ ì´ë²¤íŠ¸', 'ì¼í‰ê·  ì´ë²¤íŠ¸', 'ì‹¬ê° ì´ë²¤íŠ¸', 'ê²½ê³  ì´ë²¤íŠ¸', 'ì •ë³´ ì´ë²¤íŠ¸', 'ì˜í–¥ í˜¸ìŠ¤íŠ¸'],
                'ê°’': [f"{total_events:,}", f"{daily_avg:.1f}", f"{critical_events:,}", f"{warning_events:,}", f"{info_events:,}", f"{unique_hosts}"],
                'ë¹„ìœ¨': ['-', '-', f"{(critical_events/total_events*100):.1f}%", f"{(warning_events/total_events*100):.1f}%", f"{(info_events/total_events*100):.1f}%", '-']
            }
            summary_df = pd.DataFrame(summary_data)
            
            st.download_button(
                label="ğŸ“¥ ìš”ì•½ ë°ì´í„° ë‹¤ìš´ë¡œë“œ (CSV)",
                data=summary_df.to_csv(index=False, encoding='utf-8-sig'),
                file_name=f"ITO_ìš”ì•½ë°ì´í„°_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv"
            )

# ì—°ê²° ìƒíƒœ í™•ì¸ í•¨ìˆ˜ë“¤
def check_storage_connection():
    try:
        if not STORAGE_CONNECTION_STRING:
            return False
        blob_service_client = BlobServiceClient.from_connection_string(STORAGE_CONNECTION_STRING)
        # ê°„ë‹¨í•œ ì—°ê²° í…ŒìŠ¤íŠ¸
        list(blob_service_client.list_containers())
        return True
    except:
        return False

def check_search_connection():
    try:
        if not SEARCH_ENDPOINT or not SEARCH_KEY:
            return False
        search_client = SearchClient(
            endpoint=SEARCH_ENDPOINT,
            index_name=SEARCH_INDEX_NAME,
            credential=AzureKeyCredential(SEARCH_KEY)
        )
        return True
    except:
        return False

def check_openai_connection():
    try:
        if not OPENAI_API_KEY or not OPENAI_ENDPOINT:
            return False
        # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ìš”ì²­
        return True
    except:
        return False

# ë©”ì¸ ì•±
st.title("ğŸ” ITO ì´ë²¤íŠ¸ ë¶„ì„ agent")

# íƒ­ ìƒì„±
tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“¤ ë°ì´í„° ì—…ë¡œë“œ", "ğŸ“Š ì´ë²¤íŠ¸ ë¶„ì„", "ğŸ“ˆ ë¦¬í¬íŠ¸", "âš™ï¸ ì„¤ì •"])

with tab1:
    st.header("ì´ë²¤íŠ¸ ë¡œê·¸ ì—…ë¡œë“œ")
    
    # íŒŒì¼ ì—…ë¡œë“œ
    uploaded_files = st.file_uploader(
        "CSV íŒŒì¼ë“¤ì„ ì„ íƒí•˜ì„¸ìš”",
        type=['csv'],
        accept_multiple_files=True,
        help="í•˜ë‚˜ ë˜ëŠ” ì—¬ëŸ¬ ê°œì˜ ì´ë²¤íŠ¸ ë¡œê·¸ CSV íŒŒì¼ì„ ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤"
    )
    
    if uploaded_files:
        st.success(f"âœ… {len(uploaded_files)}ê°œì˜ íŒŒì¼ì´ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤")
        
        # ê° íŒŒì¼ ì •ë³´ ë° ë¯¸ë¦¬ë³´ê¸°
        file_data = {}
        total_events = 0
        all_hosts = set()
        
        for i, file in enumerate(uploaded_files):
            with st.expander(f"ğŸ“„ {file.name}"):
                try:
                    # ì¸ì½”ë”© ì˜µì…˜ ì‹œë„
                    encodings = ['utf-8', 'cp949', 'euc-kr', 'latin1']
                    df = None
                    
                    for encoding in encodings:
                        try:
                            file.seek(0)
                            df = pd.read_csv(file, encoding=encoding)
                            st.success(f"âœ… {encoding} ì¸ì½”ë”©ìœ¼ë¡œ ì½ê¸° ì„±ê³µ")
                            break
                        except UnicodeDecodeError:
                            continue
                        except Exception as e:
                            st.warning(f"âš ï¸ {encoding} ì¸ì½”ë”© ì‹¤íŒ¨: {str(e)}")
                    
                    if df is None:
                        st.error(f"âŒ íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì§€ì›ë˜ëŠ” ì¸ì½”ë”©: {', '.join(encodings)}")
                        continue
                    
                    file.seek(0)  # íŒŒì¼ í¬ì¸í„° ë¦¬ì…‹
                    
                    # ë°ì´í„° ê²€ì¦
                    st.write(f"ğŸ“Š ë°ì´í„° shape: {df.shape}")
                    st.write(f"ğŸ“‹ ì»¬ëŸ¼: {', '.join(df.columns.tolist())}")
                    
                    # íŒŒì¼ ì •ë³´ ì €ì¥
                    file_data[file.name] = {
                        'data': df,
                        'size': file.size,
                        'events': len(df),
                        'hosts': df['Host'].unique().tolist() if 'Host' in df.columns else []
                    }
                    
                    # ì „ì²´ í†µê³„ ì—…ë°ì´íŠ¸
                    total_events += len(df)
                    if 'Host' in df.columns:
                        all_hosts.update(df['Host'].unique())
                    
                    # íŒŒì¼ë³„ ì •ë³´ í‘œì‹œ
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("ì´ë²¤íŠ¸ ìˆ˜", f"{len(df):,}")
                    with col2:
                        st.metric("í˜¸ìŠ¤íŠ¸ ìˆ˜", df['Host'].nunique() if 'Host' in df.columns else "N/A")
                    with col3:
                        st.metric("íŒŒì¼ í¬ê¸°", f"{file.size / 1024:.2f} KB")
                    with col4:
                        if 'Time' in df.columns:
                            try:
                                df['Time'] = pd.to_datetime(df['Time'])
                                period = f"{df['Time'].min().strftime('%m/%d')} ~ {df['Time'].max().strftime('%m/%d')}"
                                st.metric("ê¸°ê°„", period)
                            except Exception as e:
                                st.metric("ê¸°ê°„", "ë‚ ì§œ í˜•ì‹ ì˜¤ë¥˜")
                        else:
                            st.metric("ê¸°ê°„", "N/A")
                    
                    # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
                    st.dataframe(df.head(5), use_container_width=True)
                    
                except Exception as e:
                    st.error(f"âŒ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {str(e)}")
                    st.info("ğŸ’¡ CSV íŒŒì¼ í˜•ì‹ì„ í™•ì¸í•˜ì„¸ìš”:\n- ì²« ì¤„ì€ í—¤ë”ì—¬ì•¼ í•©ë‹ˆë‹¤\n- ì‰¼í‘œ(,)ë¡œ êµ¬ë¶„ë˜ì–´ì•¼ í•©ë‹ˆë‹¤\n- UTF-8 ë˜ëŠ” CP949 ì¸ì½”ë”©ì´ì–´ì•¼ í•©ë‹ˆë‹¤")
        
        # ì „ì²´ ìš”ì•½ ì •ë³´
        st.markdown("---")
        st.subheader("ğŸ“Š ì „ì²´ íŒŒì¼ ìš”ì•½")
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ì´ íŒŒì¼ ìˆ˜", f"{len(uploaded_files)}ê°œ")
        with col2:
            st.metric("ì´ ì´ë²¤íŠ¸ ìˆ˜", f"{total_events:,}")
        with col3:
            st.metric("ì „ì²´ í˜¸ìŠ¤íŠ¸ ìˆ˜", f"{len(all_hosts)}ê°œ")
        
        # ë°ì´í„° ì €ì¥ ì˜µì…˜
        st.markdown("---")
        st.subheader("ğŸ’¾ ë°ì´í„° ì €ì¥ ì˜µì…˜")
        
        save_option = st.radio(
            "ë°ì´í„° ì €ì¥ ë°©ì‹",
            ["ê°œë³„ íŒŒì¼ë¡œ ìœ ì§€", "í•˜ë‚˜ë¡œ ë³‘í•©í•˜ì—¬ ì €ì¥"],
            horizontal=True,
            help="ë¶„ì„ ì‹œ ì‚¬ìš©í•  ë°ì´í„° ì €ì¥ ë°©ì‹ì„ ì„ íƒí•˜ì„¸ìš”"
        )
        
        if st.button("âœ… ë¶„ì„ ì¤€ë¹„ ì™„ë£Œ", type="primary", use_container_width=True):
            with st.spinner("ë°ì´í„°ë¥¼ ì¤€ë¹„í•˜ëŠ” ì¤‘..."):
                try:
                    if save_option == "ê°œë³„ íŒŒì¼ë¡œ ìœ ì§€":
                        # ê° íŒŒì¼ì„ ê°œë³„ì ìœ¼ë¡œ ì„¸ì…˜ì— ì €ì¥
                        st.session_state['event_files'] = file_data
                        st.session_state['data_mode'] = 'multiple'
                        st.success(f"âœ… {len(file_data)}ê°œì˜ íŒŒì¼ì´ ê°œë³„ì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                        
                    else:  # í•˜ë‚˜ë¡œ ë³‘í•©
                        # ë””ë²„ê·¸ ì •ë³´ í‘œì‹œ
                        st.write(f"ğŸ“Š ë³‘í•© ëŒ€ìƒ íŒŒì¼ ìˆ˜: {len(file_data)}")
                        for filename, data in file_data.items():
                            if 'data' in data:
                                st.write(f"  - {filename}: {len(data['data'])}í–‰, ë¹„ì–´ìˆìŒ: {data['data'].empty}")
                        
                        # ëª¨ë“  ë°ì´í„°í”„ë ˆì„ ë³‘í•©
                        all_dfs = []
                        for filename, data in file_data.items():
                            if 'data' in data and not data['data'].empty:
                                all_dfs.append(data['data'])
                                st.success(f"âœ… {filename} ì¶”ê°€ë¨")
                            else:
                                st.warning(f"âš ï¸ {filename} íŒŒì¼ì´ ë¹„ì–´ìˆê±°ë‚˜ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤.")
                        
                        if not all_dfs:
                            st.error("âŒ ë³‘í•©í•  ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
                            st.info("ğŸ’¡ íŒŒì¼ì´ ë¹„ì–´ìˆì§€ ì•Šì€ì§€, CSV í˜•ì‹ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ì„¸ìš”.")
                        else:
                            merged_df = pd.concat(all_dfs, ignore_index=True)
                            
                            # Time ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ ì •ë ¬
                            if 'Time' in merged_df.columns:
                                merged_df['Time'] = pd.to_datetime(merged_df['Time'])
                                merged_df = merged_df.sort_values('Time')
                            
                            st.session_state['event_data'] = merged_df
                            st.session_state['data_mode'] = 'single'
                            st.success(f"âœ… {len(all_dfs)}ê°œì˜ íŒŒì¼ì´ ë³‘í•©ë˜ì–´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤! (ì´ {len(merged_df)}í–‰)")
                    
                    # Azure Storage ì—…ë¡œë“œ (ì„¤ì •ëœ ê²½ìš°)
                    if STORAGE_CONNECTION_STRING and STORAGE_CONNECTION_STRING.strip():
                        try:
                            # ì—°ê²° ë¬¸ìì—´ ê²€ì¦
                            if "AccountName=" not in STORAGE_CONNECTION_STRING or "AccountKey=" not in STORAGE_CONNECTION_STRING:
                                st.warning("â˜ï¸ Storage ì—°ê²° ë¬¸ìì—´ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
                            else:
                                blob_service_client = BlobServiceClient.from_connection_string(STORAGE_CONNECTION_STRING)
                                container_name = "event-logs"
                                
                                # ì»¨í…Œì´ë„ˆ ì¡´ì¬ í™•ì¸ ë° ìƒì„±
                                container_client = blob_service_client.get_container_client(container_name)
                                try:
                                    container_client.get_container_properties()
                                except:
                                    container_client.create_container()
                                    st.info(f"â˜ï¸ '{container_name}' ì»¨í…Œì´ë„ˆë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")
                                
                                # íŒŒì¼ ì—…ë¡œë“œ
                                uploaded_count = 0
                                for filename, file_info in file_data.items():
                                    if 'data' in file_info and not file_info['data'].empty:
                                        blob_name = f"uploads/{datetime.now().strftime('%Y%m%d_%H%M%S')}_{filename}"
                                        blob_client = blob_service_client.get_blob_client(
                                            container=container_name,
                                            blob=blob_name
                                        )
                                        csv_data = file_info['data'].to_csv(index=False)
                                        blob_client.upload_blob(csv_data, overwrite=True)
                                        uploaded_count += 1
                                
                                if uploaded_count > 0:
                                    st.success(f"â˜ï¸ {uploaded_count}ê°œ íŒŒì¼ì´ í´ë¼ìš°ë“œì— ë°±ì—…ë˜ì—ˆìŠµë‹ˆë‹¤")
                        except Exception as e:
                            st.warning(f"â˜ï¸ í´ë¼ìš°ë“œ ë°±ì—… ì‹¤íŒ¨: {str(e)}")
                            st.info("ğŸ’¡ .env íŒŒì¼ì˜ STORAGE_CONNECTION_STRINGì„ í™•ì¸í•˜ì„¸ìš”")
                    
                    st.info("ğŸ’¡ ì´ì œ 'ì´ë²¤íŠ¸ ë¶„ì„' íƒ­ì—ì„œ ë¶„ì„ì„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!")
                    
                except Exception as e:
                    st.error(f"âŒ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                    st.info("ğŸ’¡ íŒ: CSV íŒŒì¼ì´ ì˜¬ë°”ë¥¸ í˜•ì‹ì¸ì§€ í™•ì¸í•˜ì„¸ìš”. í—¤ë”ê°€ ìˆê³  ë°ì´í„°ê°€ í¬í•¨ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.")

with tab2:
    st.header("ì´ë²¤íŠ¸ ë¶„ì„")
    
    # ë°ì´í„° í™•ì¸
    has_data = False
    if 'data_mode' in st.session_state:
        if st.session_state['data_mode'] == 'single' and 'event_data' in st.session_state:
            has_data = True
        elif st.session_state['data_mode'] == 'multiple' and 'event_files' in st.session_state:
            has_data = True
    elif 'event_data' in st.session_state:  # ê¸°ì¡´ í˜¸í™˜ì„±
        has_data = True
        st.session_state['data_mode'] = 'single'
    
    if not has_data:
        st.warning("âš ï¸ ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.info("ğŸ‘ˆ 'ë°ì´í„° ì—…ë¡œë“œ' íƒ­ì—ì„œ CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê±°ë‚˜, ì•„ë˜ì—ì„œ ì§ì ‘ ì—…ë¡œë“œí•˜ì„¸ìš”.")
        
        # ì—¬ê¸°ì„œë„ ì—…ë¡œë“œ ê°€ëŠ¥í•˜ë„ë¡ ì¶”ê°€
        uploaded_file = st.file_uploader(
            "CSV íŒŒì¼ì„ ì—¬ê¸°ì„œ ì§ì ‘ ì—…ë¡œë“œí•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤",
            type=['csv'],
            key="tab2_uploader"
        )
        
        if uploaded_file is not None:
            df = pd.read_csv(uploaded_file)
            st.session_state['event_data'] = df
            st.session_state['data_mode'] = 'single'
            st.success("âœ… íŒŒì¼ì´ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
            st.experimental_rerun()
    
    else:
        # ë¶„ì„í•  ë°ì´í„° ì„ íƒ (ì—¬ëŸ¬ íŒŒì¼ì¸ ê²½ìš°)
        if st.session_state.get('data_mode') == 'multiple':
            st.subheader("ğŸ“ ë¶„ì„í•  íŒŒì¼ ì„ íƒ")
            
            file_names = list(st.session_state['event_files'].keys())
            
            analysis_option = st.radio(
                "ë¶„ì„ ë°©ì‹",
                ["ê°œë³„ íŒŒì¼ ë¶„ì„", "ì„ íƒí•œ íŒŒì¼ë“¤ ë³‘í•© ë¶„ì„", "ì „ì²´ íŒŒì¼ ë³‘í•© ë¶„ì„"],
                horizontal=True
            )
            
            if analysis_option == "ê°œë³„ íŒŒì¼ ë¶„ì„":
                selected_file = st.selectbox("ë¶„ì„í•  íŒŒì¼ ì„ íƒ", file_names)
                df = st.session_state['event_files'][selected_file]['data']
                st.info(f"ğŸ“„ ì„ íƒëœ íŒŒì¼: {selected_file} ({len(df):,}ê°œ ì´ë²¤íŠ¸)")
                
            elif analysis_option == "ì„ íƒí•œ íŒŒì¼ë“¤ ë³‘í•© ë¶„ì„":
                selected_files = st.multiselect("ë¶„ì„í•  íŒŒì¼ë“¤ ì„ íƒ", file_names, default=file_names[:2] if len(file_names) >= 2 else file_names)
                if selected_files:
                    dfs = []
                    for f in selected_files:
                        if not st.session_state['event_files'][f]['data'].empty:
                            dfs.append(st.session_state['event_files'][f]['data'])
                    
                    if dfs:
                        df = pd.concat(dfs, ignore_index=True)
                        if 'Time' in df.columns:
                            df['Time'] = pd.to_datetime(df['Time'])
                            df = df.sort_values('Time')
                        st.info(f"ğŸ“„ {len(selected_files)}ê°œ íŒŒì¼ ë³‘í•© ({len(df):,}ê°œ ì´ë²¤íŠ¸)")
                    else:
                        st.warning("ì„ íƒí•œ íŒŒì¼ë“¤ì— ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        df = pd.DataFrame()
                else:
                    st.warning("ë¶„ì„í•  íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”")
                    df = pd.DataFrame()  # ë¹ˆ ë°ì´í„°í”„ë ˆì„ í• ë‹¹
                    
            else:  # ì „ì²´ íŒŒì¼ ë³‘í•© ë¶„ì„
                dfs = []
                for data in st.session_state['event_files'].values():
                    if not data['data'].empty:
                        dfs.append(data['data'])
                
                if dfs:
                    df = pd.concat(dfs, ignore_index=True)
                    if 'Time' in df.columns:
                        df['Time'] = pd.to_datetime(df['Time'])
                        df = df.sort_values('Time')
                    st.info(f"ğŸ“„ ì „ì²´ {len(dfs)}ê°œ íŒŒì¼ ë³‘í•© ({len(df):,}ê°œ ì´ë²¤íŠ¸)")
                else:
                    st.warning("ìœ íš¨í•œ ë°ì´í„°ê°€ ìˆëŠ” íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                    df = pd.DataFrame()
        
        else:  # single mode
            df = st.session_state['event_data']
        
        # ë°ì´í„°ê°€ ë¹„ì–´ìˆì§€ ì•Šì€ ê²½ìš°ì—ë§Œ ì§„í–‰
        if not df.empty:
            # ë°ì´í„° ìš”ì•½ í‘œì‹œ
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("ì´ ì´ë²¤íŠ¸", f"{len(df):,}")
            with col2:
                st.metric("í˜¸ìŠ¤íŠ¸ ìˆ˜", df['Host'].nunique() if 'Host' in df.columns else 0)
            with col3:
                critical_count = len(df[df['Severity'].isin(['Disaster', 'High'])]) if 'Severity' in df.columns else 0
                st.metric("ì‹¬ê° ì´ë²¤íŠ¸", critical_count)
            with col4:
                st.metric("ë¶„ì„ ì¤€ë¹„", "âœ… ì™„ë£Œ")
            
            # ì‹œê°„ ë²”ìœ„ í•„í„° ì¶”ê°€
            if 'Time' in df.columns:
                st.markdown("---")
                st.subheader("â° ì‹œê°„ ë²”ìœ„ í•„í„°")
                
                df['Time'] = pd.to_datetime(df['Time'])
                min_date = df['Time'].min()
                max_date = df['Time'].max()
                
                col1, col2 = st.columns(2)
                with col1:
                    start_date = st.date_input(
                        "ì‹œì‘ ë‚ ì§œ",
                        value=min_date.date(),
                        min_value=min_date.date(),
                        max_value=max_date.date()
                    )
                with col2:
                    end_date = st.date_input(
                        "ì¢…ë£Œ ë‚ ì§œ",
                        value=max_date.date(),
                        min_value=min_date.date(),
                        max_value=max_date.date()
                    )
                
                # ë‚ ì§œ í•„í„° ì ìš©
                if start_date and end_date:
                    mask = (df['Time'].dt.date >= start_date) & (df['Time'].dt.date <= end_date)
                    filtered_df = df[mask]
                    
                    if len(filtered_df) < len(df):
                        st.info(f"ğŸ” í•„í„° ì ìš©: {len(filtered_df):,}ê°œ ì´ë²¤íŠ¸ (ì „ì²´ {len(df):,}ê°œ ì¤‘)")
                        df = filtered_df
            
            # ê°„ëµí™”ëœ AI ë¶„ì„ ì„¹ì…˜
            st.markdown("---")
            st.subheader("ğŸ¤– AI ê¸°ë°˜ ë¹ ë¥¸ ë¶„ì„")
            
            col1, col2 = st.columns([3, 1])
            with col1:
                st.info("ğŸ’¡ AIê°€ í˜„ì¬ ìƒíƒœë¥¼ ë¹ ë¥´ê²Œ ì§„ë‹¨í•˜ê³  ì£¼ìš” ë¬¸ì œì ê³¼ ì¡°ì¹˜ì‚¬í•­ì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.")
            with col2:
                if st.button("ğŸš€ AI ë¶„ì„ ì‹¤í–‰", type="primary", use_container_width=True):
                    with st.spinner("AIê°€ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ëŠ” ì¤‘..."):
                        ai_result = perform_simple_ai_analysis(df)
                        
                        # ê²°ê³¼ë¥¼ ì„¸ì…˜ì— ì €ì¥
                        st.session_state['ai_analysis_result'] = ai_result
                        st.session_state['ai_analysis_time'] = datetime.now()
            
            # AI ë¶„ì„ ê²°ê³¼ í‘œì‹œ
            if 'ai_analysis_result' in st.session_state:
                st.markdown("### ğŸ“‹ AI ë¶„ì„ ê²°ê³¼")
                
                # ë¶„ì„ ì‹œê°„ í‘œì‹œ
                if 'ai_analysis_time' in st.session_state:
                    time_diff = datetime.now() - st.session_state['ai_analysis_time']
                    minutes_ago = int(time_diff.total_seconds() / 60)
                    if minutes_ago < 1:
                        time_text = "ë°©ê¸ˆ ì „"
                    else:
                        time_text = f"{minutes_ago}ë¶„ ì „"
                    st.caption(f"ğŸ• ë¶„ì„ ì‹œê°„: {time_text}")
                
                # AI ê²°ê³¼ë¥¼ ë³´ê¸° ì¢‹ê²Œ í‘œì‹œ
                with st.container():
                    # ê²°ê³¼ë¥¼ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ í‘œì‹œ
                    st.markdown(st.session_state['ai_analysis_result'])
                    
                    # ë¶„ì„ ê²°ê³¼ ìš”ì•½ ë©”íŠ¸ë¦­ (AI ì‘ë‹µì—ì„œ ì¶”ì¶œ ê°€ëŠ¥í•œ ê²½ìš°)
                    st.markdown("---")
                    
                    # ë‹¤ìš´ë¡œë“œ ì˜µì…˜
                    col1, col2, col3 = st.columns([1, 1, 2])
                    with col1:
                        st.download_button(
                            label="ğŸ“¥ ë¶„ì„ ê²°ê³¼ ì €ì¥ (TXT)",
                            data=st.session_state['ai_analysis_result'],
                            file_name=f"ai_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                            mime="text/plain"
                        )
                    
                    with col2:
                        # ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œë„ ì €ì¥
                        markdown_content = f"""# AI ì´ë²¤íŠ¸ ë¶„ì„ ë¦¬í¬íŠ¸
                        
ìƒì„±ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

---

{st.session_state['ai_analysis_result']}

---

ë³¸ ë¦¬í¬íŠ¸ëŠ” AI ê¸°ë°˜ ìë™ ë¶„ì„ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.
"""
                        st.download_button(
                            label="ğŸ“¥ ë¶„ì„ ê²°ê³¼ ì €ì¥ (MD)",
                            data=markdown_content,
                            file_name=f"ai_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md",
                            mime="text/markdown"
                        )
                
                # ì¶”ê°€ ë¶„ì„ ì˜µì…˜
                with st.expander("ğŸ” ì¶”ê°€ ë¶„ì„ ì˜µì…˜"):
                    st.info("ë” ê¹Šì€ ë¶„ì„ì´ í•„ìš”í•˜ì‹ ê°€ìš”?")
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        if st.button("ğŸ”„ ë‹¤ì‹œ ë¶„ì„", use_container_width=True):
                            with st.spinner("AIê°€ ë°ì´í„°ë¥¼ ë‹¤ì‹œ ë¶„ì„í•˜ëŠ” ì¤‘..."):
                                ai_result = perform_simple_ai_analysis(df)
                                st.session_state['ai_analysis_result'] = ai_result
                                st.session_state['ai_analysis_time'] = datetime.now()
                                st.rerun()
                    
                    with col2:
                        if st.button("ğŸ“Š í†µê³„ ë¦¬í¬íŠ¸ ìƒì„±", use_container_width=True):
                            st.info("'ë¦¬í¬íŠ¸' íƒ­ìœ¼ë¡œ ì´ë™í•˜ì—¬ ìƒì„¸ í†µê³„ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            
            st.markdown("---")
            
            # í†µê³„ ê·¸ë˜í”„ ì„¹ì…˜
            st.subheader("ğŸ“ˆ ì´ë²¤íŠ¸ í†µê³„ ë¶„ì„")
            
            # ê·¸ë˜í”„ íƒ­ ìƒì„±
            graph_tabs = st.tabs(["ì‹œê°„ëŒ€ë³„ ë¶„ì„", "í˜¸ìŠ¤íŠ¸ë³„ ë¶„ì„", "ì‹¬ê°ë„ ë¶„ì„", "íŠ¸ë Œë“œ ë¶„ì„"])
            
            with graph_tabs[0]:
                # ì‹œê°„ëŒ€ë³„ ë¶„ì„
                if 'Time' in df.columns:
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        # ì‹œê°„ë³„ ì´ë²¤íŠ¸ ë°œìƒ ìˆ˜
                        hourly_counts = df.groupby(df['Time'].dt.hour).size()
                        
                        # 0-23ì‹œê¹Œì§€ ëª¨ë“  ì‹œê°„ í¬í•¨
                        all_hours = pd.Series(0, index=range(24))
                        all_hours.update(hourly_counts)
                        
                        fig = px.bar(
                            x=all_hours.index,
                            y=all_hours.values,
                            title='ì‹œê°„ëŒ€ë³„ ì´ë²¤íŠ¸ ë°œìƒ í˜„í™©',
                            labels={'x': 'ì‹œê°„', 'y': 'ì´ë²¤íŠ¸ ìˆ˜'},
                            color=all_hours.values,
                            color_continuous_scale='Blues',
                            text=all_hours.values  # ë§‰ëŒ€ ìœ„ì— ê°’ í‘œì‹œ
                        )
                        
                        # xì¶• ì„¤ì • - 1ì‹œê°„ ë‹¨ìœ„ë¡œ í‘œì‹œ
                        fig.update_xaxes(
                            tickmode='linear',
                            tick0=0,
                            dtick=1,
                            tickformat='%d',
                            ticksuffix='ì‹œ',
                            range=[-0.5, 23.5],
                            title="ì‹œê°„ (0ì‹œ ~ 23ì‹œ)"
                        )
                        
                        # ë§‰ëŒ€ ìœ„ í…ìŠ¤íŠ¸ í‘œì‹œ ì„¤ì •
                        fig.update_traces(texttemplate='%{text}', textposition='outside')
                        
                        fig.update_layout(
                            showlegend=False,
                            yaxis=dict(title='ì´ë²¤íŠ¸ ìˆ˜'),
                            bargap=0.2
                        )
                        st.plotly_chart(fig, use_container_width=True)
                    
                    with col2:
                        # ìš”ì¼ë³„ ì´ë²¤íŠ¸ ë°œìƒ ìˆ˜
                        df_copy = df.copy()
                        df_copy['DayOfWeek'] = df_copy['Time'].dt.day_name()
                        day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
                        daily_counts = df_copy['DayOfWeek'].value_counts().reindex(day_order, fill_value=0)
                        
                        fig = px.line(
                            x=daily_counts.index,
                            y=daily_counts.values,
                            title='ìš”ì¼ë³„ ì´ë²¤íŠ¸ ë°œìƒ ì¶”ì´',
                            labels={'x': 'ìš”ì¼', 'y': 'ì´ë²¤íŠ¸ ìˆ˜'},
                            markers=True
                        )
                        st.plotly_chart(fig, use_container_width=True)
                    
                    # ì‹œê³„ì—´ íˆíŠ¸ë§µ
                    df_heatmap = df.copy()
                    df_heatmap['Date'] = df_heatmap['Time'].dt.date
                    df_heatmap['Hour'] = df_heatmap['Time'].dt.hour
                    heatmap_data = df_heatmap.groupby(['Date', 'Hour']).size().unstack(fill_value=0)
                    
                    # ëª¨ë“  ì‹œê°„(0-23)ì´ í¬í•¨ë˜ë„ë¡ ë³´ì¥
                    for hour in range(24):
                        if hour not in heatmap_data.columns:
                            heatmap_data[hour] = 0
                    heatmap_data = heatmap_data.reindex(columns=range(24), fill_value=0)
                    
                    fig = px.imshow(
                        heatmap_data.T,
                        title='ì¼ë³„/ì‹œê°„ë³„ ì´ë²¤íŠ¸ íˆíŠ¸ë§µ',
                        labels=dict(x="ë‚ ì§œ", y="ì‹œê°„", color="ì´ë²¤íŠ¸ ìˆ˜"),
                        aspect="auto",
                        color_continuous_scale='Reds'
                    )
                    
                    # yì¶•ì„ ì‹œê°„ í˜•ì‹ìœ¼ë¡œ í‘œì‹œ
                    fig.update_yaxes(
                        tickmode='array',
                        tickvals=list(range(24)),
                        ticktext=[f'{i:02d}:00' for i in range(24)],
                        title="ì‹œê°„ (24ì‹œê°„ í˜•ì‹)"
                    )
                    
                    # xì¶• ë‚ ì§œ í˜•ì‹ ê°œì„ 
                    fig.update_xaxes(
                        tickformat='%m/%d',
                        title="ë‚ ì§œ"
                    )
                    
                    st.plotly_chart(fig, use_container_width=True)
            
            with graph_tabs[1]:
                # í˜¸ìŠ¤íŠ¸ë³„ ë¶„ì„
                if 'Host' in df.columns:
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        # Top 10 í˜¸ìŠ¤íŠ¸
                        top_hosts = df['Host'].value_counts().head(10)
                        fig = px.bar(
                            y=top_hosts.index,
                            x=top_hosts.values,
                            orientation='h',
                            title='Top 10 ì´ë²¤íŠ¸ ë°œìƒ í˜¸ìŠ¤íŠ¸',
                            labels={'x': 'ì´ë²¤íŠ¸ ìˆ˜', 'y': 'í˜¸ìŠ¤íŠ¸'},
                            color=top_hosts.values,
                            color_continuous_scale='Reds'
                        )
                        fig.update_layout(showlegend=False)
                        st.plotly_chart(fig, use_container_width=True)
                    
                    with col2:
                        # í˜¸ìŠ¤íŠ¸ë³„ ì‹¬ê°ë„ ë¶„í¬
                        if 'Severity' in df.columns:
                            host_severity = pd.crosstab(df['Host'], df['Severity'])
                            top_hosts_list = df['Host'].value_counts().head(5).index
                            
                            fig = go.Figure()
                            for severity in ['Disaster', 'High', 'Average', 'Warning', 'Information', 'Not classified']:
                                if severity in host_severity.columns:
                                    fig.add_trace(go.Bar(
                                        name=severity,
                                        x=host_severity.loc[top_hosts_list, severity].values if severity in host_severity.columns else [0]*5,
                                        y=top_hosts_list,
                                        orientation='h'
                                    ))
                            
                            fig.update_layout(
                                barmode='stack',
                                title='Top 5 í˜¸ìŠ¤íŠ¸ì˜ ì‹¬ê°ë„ë³„ ì´ë²¤íŠ¸ ë¶„í¬',
                                xaxis_title='ì´ë²¤íŠ¸ ìˆ˜',
                                yaxis_title='í˜¸ìŠ¤íŠ¸'
                            )
                            st.plotly_chart(fig, use_container_width=True)
            
            with graph_tabs[2]:
                # ì‹¬ê°ë„ ë¶„ì„ - ë‹¤ì–‘í•œ ì»¬ëŸ¼ëª… ì§€ì›
                severity_col = None
                possible_severity_cols = ['Severity', 'severity', 'SEVERITY', 'ì‹¬ê°ë„', 'Level', 'level']
                
                for col in possible_severity_cols:
                    if col in df.columns:
                        severity_col = col
                        break
                
                if severity_col:
                    st.markdown("### ğŸ¯ Severity ë¶„ì„")
                    
                    # ë””ë²„ê¹… ì •ë³´
                    st.caption(f"ë¶„ì„ ì»¬ëŸ¼: {severity_col}")
                    
                    # ì‹¬ê°ë„ë³„ ë¶„í¬ ê³„ì‚° (ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´)
                    df_severity = df.copy()
                    df_severity[severity_col] = df_severity[severity_col].astype(str).str.lower().str.strip()
                    severity_counts = df_severity[severity_col].value_counts()
                    total_events = len(df)
                    
                    # ê³ ìœ  ê°’ í™•ì¸
                    st.caption(f"ë°œê²¬ëœ Severity ê°’: {', '.join(severity_counts.index.tolist())}")
                    
                    # ìƒ‰ìƒ ë§¤í•‘ (ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´)
                    colors = {
                        'fatal': '#E45959',
                        'critical': '#E97659', 
                        'major': '#FFA059',
                        'information': '#7499FF',
                        'info': '#7499FF',
                        'warning': '#FFC859',
                        'error': '#E45959',
                        'high': '#E97659',
                        'medium': '#FFA059',
                        'low': '#7499FF'
                    }
                    
                    # Severity ìˆœì„œ ì •ì˜ (ìœ„í—˜ë„ ìˆœ)
                    severity_order = ['fatal', 'critical', 'major', 'information']
                    
                    # ë°ì´í„° ì¤€ë¹„
                    severity_data = []
                    for severity in severity_counts.index:
                        count = severity_counts[severity]
                        percentage = (count / total_events * 100)
                        severity_data.append({
                            'Severity': severity,
                            'Count': count,
                            'Percentage': percentage
                        })
                    
                    if severity_data:
                        severity_df = pd.DataFrame(severity_data)
                        
                        # 1. ë„ë„› ì°¨íŠ¸
                        fig = go.Figure(data=[go.Pie(
                            labels=[s['Severity'].upper() for s in severity_data],
                            values=[s['Count'] for s in severity_data],
                            hole=0.5,
                            marker=dict(
                                colors=[colors.get(s['Severity'], '#999999') for s in severity_data],
                                line=dict(color='white', width=2)
                            ),
                            texttemplate='<b>%{label}</b><br>%{value:,}<br>(%{percent})',
                            textposition='outside',
                            textfont=dict(size=16),
                            hovertemplate='<b>%{label}</b><br>' +
                                         'ì´ë²¤íŠ¸ ìˆ˜: %{value:,}ê±´<br>' +
                                         'ë¹„ìœ¨: %{percent}<br>' +
                                         '<extra></extra>',
                            sort=False
                        )])
                        
                        # ì¤‘ì•™ ì •ë³´
                        fig.add_annotation(
                            text=f'<b>ì „ì²´ ì´ë²¤íŠ¸</b><br>{total_events:,}ê±´',
                            x=0.5, y=0.5,
                            font=dict(size=20),
                            showarrow=False
                        )
                        
                        fig.update_layout(
                            title='Severity ë¶„í¬',
                            height=500,
                            showlegend=True,
                            legend=dict(
                                orientation="v",
                                yanchor="middle",
                                y=0.5,
                                xanchor="left",
                                x=1.05
                            )
                        )
                        
                        st.plotly_chart(fig, use_container_width=True)
                        
                        # 2. Severityë³„ ë©”íŠ¸ë¦­
                        st.markdown("#### ğŸ“Š Severityë³„ í˜„í™©")
                        
                        # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” severityë§Œ í‘œì‹œ
                        cols = st.columns(min(len(severity_counts), 4))
                        for idx, (severity, count) in enumerate(severity_counts.items()):
                            if idx < len(cols):
                                percentage = (count / total_events * 100) if total_events > 0 else 0
                                
                                with cols[idx]:
                                    # ìƒ‰ìƒê³¼ ì•„ì´ì½˜
                                    color = colors.get(severity, '#999999')
                                    if severity in ['fatal', 'error']:
                                        icon = "ğŸš¨"
                                    elif severity in ['critical', 'high']:
                                        icon = "âš ï¸"
                                    elif severity in ['major', 'medium', 'warning']:
                                        icon = "ğŸ“Œ"
                                    else:
                                        icon = "â„¹ï¸"
                                    
                                    st.metric(
                                        f"{icon} {severity.upper()}",
                                        f"{count:,}",
                                        f"{percentage:.1f}%"
                                    )
                        
                        # 3. ìƒì„¸ í…Œì´ë¸”
                        st.markdown("#### ğŸ“‹ Severity ìƒì„¸ ë¶„ì„")
                        
                        # í…Œì´ë¸” ë°ì´í„° ìƒì„±
                        table_data = []
                        cumulative_pct = 0
                        
                        for severity, count in severity_counts.items():
                            percentage = (count / total_events * 100)
                            cumulative_pct += percentage
                            
                            table_data.append({
                                'Severity': severity.upper(),
                                'ì´ë²¤íŠ¸ ìˆ˜': f"{count:,}",
                                'ë¹„ìœ¨(%)': f"{percentage:.2f}%",
                                'ëˆ„ì  ë¹„ìœ¨(%)': f"{cumulative_pct:.2f}%"
                            })
                        
                        if table_data:
                            table_df = pd.DataFrame(table_data)
                            st.dataframe(table_df, use_container_width=True, hide_index=True)
                        
                        # 4. ì£¼ìš” ì¸ì‚¬ì´íŠ¸
                        st.markdown("#### ğŸ’¡ ë¶„ì„ ê²°ê³¼")
                        
                        # ìœ„í—˜ ë ˆë²¨ ê³„ì‚° (ë‹¤ì–‘í•œ ì´ë¦„ ì§€ì›)
                        high_risk_keywords = ['fatal', 'critical', 'error', 'high', 'disaster']
                        medium_risk_keywords = ['major', 'warning', 'medium', 'average']
                        
                        high_risk_count = sum(severity_counts.get(k, 0) for k in high_risk_keywords if k in severity_counts.index)
                        high_risk_pct = (high_risk_count / total_events * 100) if total_events > 0 else 0
                        
                        if high_risk_pct > 20:
                            st.error(f"âš ï¸ ê³ ìœ„í—˜ ì´ë²¤íŠ¸ê°€ {high_risk_pct:.1f}%ë¡œ ë§¤ìš° ë†’ìŠµë‹ˆë‹¤. ì¦‰ê°ì ì¸ ëŒ€ì‘ì´ í•„ìš”í•©ë‹ˆë‹¤.")
                        elif high_risk_pct > 10:
                            st.warning(f"ğŸ“Œ ê³ ìœ„í—˜ ì´ë²¤íŠ¸ê°€ {high_risk_pct:.1f}%ì…ë‹ˆë‹¤. ì£¼ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                        else:
                            st.success(f"âœ… ê³ ìœ„í—˜ ì´ë²¤íŠ¸ê°€ {high_risk_pct:.1f}%ë¡œ ì•ˆì •ì ì…ë‹ˆë‹¤.")
                        
                        # ê°€ì¥ ë§ì€ severity
                        if len(severity_counts) > 0:
                            top_severity = severity_counts.index[0]
                            top_pct = (severity_counts.iloc[0] / total_events * 100)
                            st.info(f"ğŸ“Š ê°€ì¥ ë§ì€ ì´ë²¤íŠ¸: **{top_severity.upper()}** ({top_pct:.1f}%)")
                    
                    else:
                        st.warning("Severity ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                else:
                    st.warning("âŒ Severity ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    st.info(f"ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {', '.join(df.columns.tolist())}")
            
            with graph_tabs[3]:
                # íŠ¸ë Œë“œ ë¶„ì„
                if 'Time' in df.columns:
                    # ì¼ë³„ ì´ë²¤íŠ¸ íŠ¸ë Œë“œ
                    daily_events = df.groupby(df['Time'].dt.date).size()
                    
                    fig = go.Figure()
                    fig.add_trace(go.Scatter(
                        x=daily_events.index,
                        y=daily_events.values,
                        mode='lines+markers',
                        name='ì¼ë³„ ì´ë²¤íŠ¸',
                        line=dict(color='blue', width=2),
                        marker=dict(size=6)
                    ))
                    
                    # ì´ë™ í‰ê·  ì¶”ê°€
                    ma7 = daily_events.rolling(window=7, min_periods=1).mean()
                    fig.add_trace(go.Scatter(
                        x=ma7.index,
                        y=ma7.values,
                        mode='lines',
                        name='7ì¼ ì´ë™í‰ê· ',
                        line=dict(color='red', width=2, dash='dash')
                    ))
                    
                    fig.update_layout(
                        title='ì¼ë³„ ì´ë²¤íŠ¸ ë°œìƒ íŠ¸ë Œë“œ',
                        xaxis_title='ë‚ ì§œ',
                        yaxis_title='ì´ë²¤íŠ¸ ìˆ˜',
                        hovermode='x unified'
                    )
                    
                    # xì¶• ë‚ ì§œ í˜•ì‹ ì„¤ì •
                    fig.update_xaxes(
                        tickformat='%Y-%m-%d',
                        tickangle=45,
                        dtick='D1'  # 1ì¼ ë‹¨ìœ„ë¡œ í‘œì‹œ
                    )
                    
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # ì‹¬ê°ë„ë³„ íŠ¸ë Œë“œ
                    if 'Severity' in df.columns:
                        severity_trend = df.groupby([df['Time'].dt.date, 'Severity']).size().unstack(fill_value=0)
                        
                        fig = go.Figure()
                        for severity in ['Disaster', 'High', 'Average', 'Warning']:
                            if severity in severity_trend.columns:
                                fig.add_trace(go.Scatter(
                                    x=severity_trend.index,
                                    y=severity_trend[severity],
                                    mode='lines',
                                    name=severity,
                                    stackgroup='one'
                                ))
                        
                        fig.update_layout(
                            title='ì‹¬ê°ë„ë³„ ì´ë²¤íŠ¸ ë°œìƒ íŠ¸ë Œë“œ',
                            xaxis_title='ë‚ ì§œ',
                            yaxis_title='ì´ë²¤íŠ¸ ìˆ˜',
                            hovermode='x unified'
                        )
                        st.plotly_chart(fig, use_container_width=True)

with tab3:
    st.header("íŠ¸ë Œë“œ ë° í†µê³„ ë¦¬í¬íŠ¸")
    
    # ë°ì´í„° í™•ì¸
    if 'event_data' not in st.session_state and 'event_files' not in st.session_state:
        st.warning("âš ï¸ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.info("ğŸ‘ˆ 'ë°ì´í„° ì—…ë¡œë“œ' íƒ­ì—ì„œ CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    else:
        st.markdown("### ğŸ“Š ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±")
        st.info("í˜„ì¬ ì—…ë¡œë“œëœ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¢…í•© í†µê³„ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
        
        if st.button("ğŸ“¥ ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±", type="primary", use_container_width=True):
            generate_report("ì¢…í•© ë¦¬í¬íŠ¸")

with tab4:
    st.header("ì‹œìŠ¤í…œ ì„¤ì •")
    
    # ì—°ê²° ìƒíƒœ í™•ì¸
    st.subheader("ì—°ê²° ìƒíƒœ")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        storage_status = check_storage_connection()
        if storage_status:
            st.success("âœ… Storage Account ì—°ê²°ë¨")
        else:
            st.error("âŒ Storage Account ì—°ê²° ì‹¤íŒ¨")
    
    with col2:
        search_status = check_search_connection()
        if search_status:
            st.success("âœ… AI Search ì—°ê²°ë¨")
        else:
            st.error("âŒ AI Search ì—°ê²° ì‹¤íŒ¨")
    
    with col3:
        openai_status = check_openai_connection()
        if openai_status:
            st.success("âœ… OpenAI ì—°ê²°ë¨")
        else:
            st.error("âŒ OpenAI ì—°ê²° ì‹¤íŒ¨")
    
    # í™˜ê²½ ë³€ìˆ˜ ì„¤ì • ê°€ì´ë“œ
    if not all([storage_status, search_status, openai_status]):
        st.warning("âš ï¸ ì¼ë¶€ ì„œë¹„ìŠ¤ê°€ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        st.markdown("""
        ### í™˜ê²½ ë³€ìˆ˜ ì„¤ì • ê°€ì´ë“œ
        
        `.env` íŒŒì¼ì„ ìƒì„±í•˜ê³  ë‹¤ìŒ ì •ë³´ë¥¼ ì…ë ¥í•˜ì„¸ìš”:
        
        ```
        STORAGE_CONNECTION_STRING="your_storage_connection_string"
        SEARCH_ENDPOINT="https://your-search-service.search.windows.net"
        SEARCH_KEY="your_search_api_key"
        OPENAI_API_KEY="your_openai_api_key"
        OPENAI_ENDPOINT="https://your-openai-resource.openai.azure.com/"
        OPENAI_DEPLOYMENT="gpt-4o-deployment"
        ```
        """)

# ì‚¬ì´ë“œë°”
st.sidebar.markdown("### ITO ì´ë²¤íŠ¸ ë¶„ì„ agent")

st.sidebar.markdown("---")
st.sidebar.markdown("v1.1.1")

if __name__ == "__main__":
    pass